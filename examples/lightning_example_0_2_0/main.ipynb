{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# need to set before importing monarch\n",
    "os.environ[\"MONARCH_FILE_LOG\"] = \"debug\"\n",
    "os.environ[\"HYPERACTOR_MESH_ENABLE_LOG_FORWARDING\"] = \"true\"\n",
    "os.environ[\"HYPERACTOR_MESH_ENABLE_FILE_CAPTURE\"] = \"true\"\n",
    "os.environ[\"HYPERACTOR_MESH_TAIL_LOG_LINES\"] = \"100\"\n",
    "\n",
    "import socket\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from utils import get_host_ip_addr, bootstrap_addr\n",
    "from monarch.actor import Actor, enable_transport, endpoint\n",
    "from monarch._src.actor.bootstrap import attach_to_workers\n",
    "\n",
    "class Hello(Actor):\n",
    "    @endpoint\n",
    "    def hello(self) -> str:\n",
    "        print(\"HELLO!\")\n",
    "        return \"echo\"\n",
    "\n",
    "\n",
    "port = 26600\n",
    "host_ip_addr = get_host_ip_addr(addr_type=\"public\")\n",
    "enable_transport(f\"tcp://{host_ip_addr}:{port}@tcp://0.0.0.0:{port}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo that we can start a bootstrap on this host, by running it in different process.\n",
    "# good for quick validation.\n",
    "\n",
    "print(f\"current PID is: {os.getpid()}\")\n",
    "\n",
    "#  worker and client can use the same port if they are on different hosts.\n",
    "worker_port = 26601\n",
    "\n",
    "python_command = f'from utils import bootstrap; bootstrap({worker_port}, \"public\")'\n",
    "ip = get_host_ip_addr(addr_type=\"public\")\n",
    "worker_addr = bootstrap_addr(ip, worker_port)\n",
    "\n",
    "proc = subprocess.Popen(\n",
    "    [\n",
    "        sys.executable,\n",
    "        \"-c\",\n",
    "        python_command,\n",
    "    ],\n",
    "    env={\n",
    "        \"MONARCH_FILE_LOG\": \"debug\",\n",
    "        \"HYPERACTOR_MESH_ENABLE_LOG_FORWARDING\": \"true\",\n",
    "        \"HYPERACTOR_MESH_ENABLE_FILE_CAPTURE\": \"true\",\n",
    "        \"HYPERACTOR_MESH_TAIL_LOG_LINES\": \"100\",\n",
    "    },\n",
    "    start_new_session=True,\n",
    ")\n",
    "\n",
    "print(f\"a worker host is running on pid {proc.pid}\")\n",
    "\n",
    "host_mesh = attach_to_workers(\n",
    "    name=\"host_mesh\", ca=\"trust_all_connections\", workers=[worker_addr]\n",
    ")\n",
    "\n",
    "proc_mesh = host_mesh.spawn_procs()\n",
    "await proc_mesh.logging_option(stream_to_client=True, aggregate_window_sec=3)\n",
    "\n",
    "hello = proc_mesh.spawn(\"hello\", Hello)\n",
    "for i in range(100):\n",
    "    hello.hello.call().get()\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "for i in range(100):\n",
    "    hello.hello.call().get()\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "proc_mesh.stop().get()\n",
    "host_mesh.shutdown().get()\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job has not been created by the user\n",
      "Launching MMT job with 4 nodes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Multi-Machine Job was successfully launched. View it at https://lightning.ai/meta-ai/general/jobs/ali_cpu_monarch | 0.2.0rc1 | 04?app_id=mmt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job started with ID: ali_cpu_monarch | 0.2.0rc1 | 04\n",
      "Job status: Pending\n",
      "Job launched. You can monitor it using: job.status\n",
      "To stop the job: job.stop()\n",
      "To clean up: studio.stop()\n"
     ]
    }
   ],
   "source": [
    "from mmt_utils import launch_mmt_job\n",
    "\n",
    "job, studio = launch_mmt_job(\n",
    "    num_nodes=4,\n",
    "    mmt_job_name=\"ali_cpu_monarch | 0.2.0rc1 | 04\",\n",
    "    port=26600,\n",
    ")\n",
    "\n",
    "print(f\"Job launched. You can monitor it using: job.status\")\n",
    "print(f\"To stop the job: job.stop()\")\n",
    "print(f\"To clean up: studio.stop()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Status.Running: 'Running'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['35.224.235.249', '34.30.180.30', '34.46.93.138', '34.44.251.41']\n",
      "['tcp://35.224.235.249:26600@tcp://0.0.0.0:26600', 'tcp://34.30.180.30:26600@tcp://0.0.0.0:26600', 'tcp://34.46.93.138:26600@tcp://0.0.0.0:26600', 'tcp://34.44.251.41:26600@tcp://0.0.0.0:26600']\n"
     ]
    }
   ],
   "source": [
    "port = 26600\n",
    "\n",
    "ip_addresses_list_public = [machine.public_ip for machine in job.machines]\n",
    "print(ip_addresses_list_public)\n",
    "worker_addrs = [f\"tcp://{ip}:{port}@tcp://0.0.0.0:{port}\" for ip in ip_addresses_list_public]\n",
    "print(worker_addrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monarch internal logs are being written to /tmp/alisol/monarch_log.log; execution id alisol_Dec-19_06:59_175\n"
     ]
    }
   ],
   "source": [
    "host_mesh = attach_to_workers(\n",
    "    name=\"host_mesh\", ca=\"trust_all_connections\", workers=worker_addrs\n",
    ")\n",
    "\n",
    "proc_mesh = host_mesh.spawn_procs(per_host={\"gpus\": 8})\n",
    "await proc_mesh.logging_option(stream_to_client=True, aggregate_window_sec=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<monarch._src.actor.v1.proc_mesh.ProcMesh at 0x76a940bbb770>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m>>> Aggregated Logs (2025-12-19 07:03:57) >>>\u001b[0m\n",
      "\u001b[33m[11 similar log lines]\u001b[0m [6] HELLO!\n",
      "\u001b[33m[4 similar log lines]\u001b[0m [30] HELLO!\n",
      "\u001b[33m[10 similar log lines]\u001b[0m [28] HELLO!\n",
      "\u001b[33m[7 similar log lines]\u001b[0m [15] HELLO!\n",
      "\u001b[36m<<< Aggregated Logs (2025-12-19 07:04:02) <<<\u001b[0m\n",
      "\n",
      "\u001b[36m>>> Aggregated Logs (2025-12-19 07:04:02) >>>\u001b[0m\n",
      "\u001b[33m[1 similar log lines]\u001b[0m [0] HELLO!\n",
      "\u001b[36m<<< Aggregated Logs (2025-12-19 07:04:30) <<<\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ValueMesh({hosts: 4, gpus: 8}):\n",
       "  (({'hosts': 0/4, 'gpus': 0/8}, 'echo'),\n",
       "   ({'hosts': 0/4, 'gpus': 1/8}, 'echo'),\n",
       "   ({'hosts': 0/4, 'gpus': 2/8}, 'echo'),\n",
       "   ({'hosts': 0/4, 'gpus': 3/8}, 'echo'),\n",
       "   ({'hosts': 0/4, 'gpus': 4/8}, 'echo'),\n",
       "   ({'hosts': 0/4, 'gpus': 5/8}, 'echo'),\n",
       "   ({'hosts': 0/4, 'gpus': 6/8}, 'echo'),\n",
       "   ({'hosts': 0/4, 'gpus': 7/8}, 'echo'),\n",
       "   ({'hosts': 1/4, 'gpus': 0/8}, 'echo'),\n",
       "   ({'hosts': 1/4, 'gpus': 1/8}, 'echo'),\n",
       "   ({'hosts': 1/4, 'gpus': 2/8}, 'echo'),\n",
       "   ({'hosts': 1/4, 'gpus': 3/8}, 'echo'),\n",
       "   ({'hosts': 1/4, 'gpus': 4/8}, 'echo'),\n",
       "   ({'hosts': 1/4, 'gpus': 5/8}, 'echo'),\n",
       "   ({'hosts': 1/4, 'gpus': 6/8}, 'echo'),\n",
       "   ({'hosts': 1/4, 'gpus': 7/8}, 'echo'),\n",
       "   ({'hosts': 2/4, 'gpus': 0/8}, 'echo'),\n",
       "   ({'hosts': 2/4, 'gpus': 1/8}, 'echo'),\n",
       "   ({'hosts': 2/4, 'gpus': 2/8}, 'echo'),\n",
       "   ({'hosts': 2/4, 'gpus': 3/8}, 'echo'),\n",
       "   ({'hosts': 2/4, 'gpus': 4/8}, 'echo'),\n",
       "   ({'hosts': 2/4, 'gpus': 5/8}, 'echo'),\n",
       "   ({'hosts': 2/4, 'gpus': 6/8}, 'echo'),\n",
       "   ({'hosts': 2/4, 'gpus': 7/8}, 'echo'),\n",
       "   ({'hosts': 3/4, 'gpus': 0/8}, 'echo'),\n",
       "   ({'hosts': 3/4, 'gpus': 1/8}, 'echo'),\n",
       "   ({'hosts': 3/4, 'gpus': 2/8}, 'echo'),\n",
       "   ({'hosts': 3/4, 'gpus': 3/8}, 'echo'),\n",
       "   ({'hosts': 3/4, 'gpus': 4/8}, 'echo'),\n",
       "   ({'hosts': 3/4, 'gpus': 5/8}, 'echo'),\n",
       "   ({'hosts': 3/4, 'gpus': 6/8}, 'echo'),\n",
       "   ({'hosts': 3/4, 'gpus': 7/8}, 'echo'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m>>> Aggregated Logs (2025-12-19 07:04:30) >>>\u001b[0m\n",
      "\u001b[33m[10 similar log lines]\u001b[0m [3] HELLO!\n",
      "\u001b[33m[12 similar log lines]\u001b[0m [24] HELLO!\n",
      "\u001b[33m[9 similar log lines]\u001b[0m [12] HELLO!\n",
      "\u001b[36m<<< Aggregated Logs (2025-12-19 07:04:31) <<<\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "actor_mesh = proc_mesh.spawn(\"hello\", Hello)\n",
    "actor_mesh.hello.call().get()\n",
    "time.sleep(30)\n",
    "actor_mesh.hello.call().get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m>>> Aggregated Logs (2025-12-19 07:04:31) >>>\u001b[0m\n",
      "\u001b[33m[1 similar log lines]\u001b[0m [3] HELLO!\n",
      "\u001b[36m<<< Aggregated Logs (2025-12-19 07:05:09) <<<\u001b[0m\n",
      "\n",
      "\u001b[36m>>> Aggregated Logs (2025-12-19 07:05:09) >>>\u001b[0m\n",
      "\u001b[33m[1800 similar log lines]\u001b[0m [2] HELLO!\n",
      "\u001b[33m[1200 similar log lines]\u001b[0m [10] HELLO!\n",
      "\u001b[33m[199 similar log lines]\u001b[0m [31] HELLO!\n",
      "\u001b[36m<<< Aggregated Logs (2025-12-19 07:05:12) <<<\u001b[0m\n",
      "\n",
      "\u001b[36m>>> Aggregated Logs (2025-12-19 07:05:12) >>>\u001b[0m\n",
      "\u001b[33m[1 similar log lines]\u001b[0m [6] HELLO!\n",
      "\u001b[36m<<< Aggregated Logs (2025-12-19 07:05:20) <<<\u001b[0m\n",
      "\n",
      "\u001b[36m>>> Aggregated Logs (2025-12-19 07:05:20) >>>\u001b[0m\n",
      "\u001b[33m[702 similar log lines]\u001b[0m [7] HELLO!\n",
      "\u001b[33m[1200 similar log lines]\u001b[0m [13] HELLO!\n",
      "\u001b[33m[998 similar log lines]\u001b[0m [24] HELLO!\n",
      "\u001b[33m[299 similar log lines]\u001b[0m [30] HELLO!\n",
      "\u001b[36m<<< Aggregated Logs (2025-12-19 07:05:22) <<<\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _i in range(100):\n",
    "    actor_mesh.hello.call().get()\n",
    "time.sleep(10)\n",
    "for _i in range(100):\n",
    "    actor_mesh.hello.call().get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_mesh.stop().get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_mesh.shutdown().get()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
